## Indeed-HackerRank

### Readme

This is code for HackerRank Indeed contest:

https://www.hackerrank.com/contests/indeed-ml-codesprint-2017/challenges/tagging-raw-job-descriptions

The contest has already finished when I found it, but the task was interest. So I explored train data and tried to predict solutions at hold-out set from train.

This challenge asks for a machine learning solution to accurately assign tags given the information in the job descriptions. We are interested in only these twelve tags:

part-time-job

full-time-job

hourly-wage

salary

associate-needed

bs-degree-needed

ms-or-phd-needed

licence-needed

1-year-experience-needed

2-4-years-experience-needed

5-plus-years-experience-needed

supervising-job

Steps of data preprocessing, model calculating, my assumptions and conclusions are below.

indeed.ipynb contains the main solution and predict evaluations with LinearSVC classifier.

base_indeed.ipynb provides predictions using basic vocabulary.


#### About data

At forum we can find the information about data: "I guess that the tags in training sets are generated by some machine learning
algorithms in Indeed. It looks that the best precision and recall we have achieved here are about 0.7, which leads to
a F1 score of 0.7. I doubt that it is hard to get higher F1 score because the mis-classifications in training sets. It is
also possible that there are similar mis-classifications in test sets".

#### Data Pre-processing
The task is considered as binary classification for each tag. I used SnowBallStemmer from NLTK library for text
stemming. CountVectorizer from Scikit-Learning is used to convert a collection of text documents (use features from 1-gram, 2-grams and 3-grams).
TfidfTransformer is used to transform a count matrix to a normalized tf or tf-idf representation.

#### LinearSVC
LinearSVC gave a better result than LogisticRegression. Using muliclass SVM at experience tags gives a slightly better result than whothout multiclass classification. 
The best result: recall 0.60357, precision 0.47271, f1-score 0.53019
One of the reasons of low result may be a small amount of data (I had to use train-test-split on train-data, so the classifier "saw" only ~3000 objests).

#### Basic solution
Prediction by presence with keywords filters: 

[[”part time”, ”part-time”], [”full time”, ”full-time”], [”hourly”,
”hour”], [”salary”], [”associate ”], [”bachelor”, ” bs ”, ”/bs ” ” bs/”], [”master”, ”phd”], [”licence”, ”license”, ”certif”,
”eligible”], [”1 year”, ”one year”], [”2 years” , ”3 years” ,”4 years”, ”two years” , ”three years” ,”four years”, ”2+
years”, ”3+ years”, ”4+ years”], [”5 years”, ”5+ years”, ”five years”, ”0 years”], [”supervi”, "manager"]]

The best result:
recall 0.48907 precision 0.68924 f1_score 0.57215

#### What should I try  else
LSTM



